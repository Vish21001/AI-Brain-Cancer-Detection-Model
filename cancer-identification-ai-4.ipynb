{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# Settings\nIMG_SIZE = 224\nBATCH_SIZE = 32\nEPOCHS = 15  # Start with 15, can increase to 25-30\nTRAIN_DIR = '/kaggle/input/brain-tumor-mri-dataset/Training'\nVAL_DIR = '/kaggle/input/brain-tumor-mri-dataset/Testing'\nNUM_CLASSES = 4\n\n# Data Augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_DIR,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical'\n)\n\nval_generator = val_datagen.flow_from_directory(\n    VAL_DIR,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical'\n)\n\n# Transfer Learning Model\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\nbase_model.trainable = False  # Freeze base\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.4)(x)  # helps reduce overfitting\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.3)(x)\npredictions = Dense(NUM_CLASSES, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile Model\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Train Top Layers\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE\n)\n\n# Fine-tune Some Base Layers\n# Unfreeze last few layers for fine-tuning\nbase_model.trainable = True\nfor layer in base_model.layers[:-20]:\n    layer.trainable = False\n\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-5),  # lower LR for fine-tuning\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Fine-tune\nhistory_fine = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:02:55.626512Z","iopub.execute_input":"2025-12-07T02:02:55.626836Z","iopub.status.idle":"2025-12-07T03:35:47.992585Z","shell.execute_reply.started":"2025-12-07T02:02:55.626810Z","shell.execute_reply":"2025-12-07T03:35:47.991516Z"}},"outputs":[{"name":"stdout","text":"Found 5712 images belonging to 4 classes.\nFound 1311 images belonging to 4 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 960ms/step - accuracy: 0.4573 - loss: 1.3402 - val_accuracy: 0.7361 - val_loss: 0.6486\nEpoch 2/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 945ms/step - accuracy: 0.7620 - loss: 0.6310 - val_accuracy: 0.7643 - val_loss: 0.5714\nEpoch 3/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 944ms/step - accuracy: 0.8056 - loss: 0.5140 - val_accuracy: 0.7948 - val_loss: 0.5115\nEpoch 4/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1s/step - accuracy: 0.8266 - loss: 0.4610 - val_accuracy: 0.7887 - val_loss: 0.5401\nEpoch 5/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 1s/step - accuracy: 0.8377 - loss: 0.4330 - val_accuracy: 0.8230 - val_loss: 0.4680\nEpoch 6/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 941ms/step - accuracy: 0.8462 - loss: 0.4110 - val_accuracy: 0.8299 - val_loss: 0.4478\nEpoch 7/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 947ms/step - accuracy: 0.8408 - loss: 0.4136 - val_accuracy: 0.8223 - val_loss: 0.4671\nEpoch 8/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 1s/step - accuracy: 0.8543 - loss: 0.3912 - val_accuracy: 0.8177 - val_loss: 0.4694\nEpoch 9/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 946ms/step - accuracy: 0.8648 - loss: 0.3558 - val_accuracy: 0.8192 - val_loss: 0.4742\nEpoch 10/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1s/step - accuracy: 0.8662 - loss: 0.3544 - val_accuracy: 0.8268 - val_loss: 0.4453\nEpoch 11/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 948ms/step - accuracy: 0.8725 - loss: 0.3357 - val_accuracy: 0.8375 - val_loss: 0.4161\nEpoch 12/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 952ms/step - accuracy: 0.8730 - loss: 0.3282 - val_accuracy: 0.8337 - val_loss: 0.4221\nEpoch 13/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step - accuracy: 0.8706 - loss: 0.3382 - val_accuracy: 0.8207 - val_loss: 0.4410\nEpoch 14/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 1s/step - accuracy: 0.8728 - loss: 0.3451 - val_accuracy: 0.8345 - val_loss: 0.4284\nEpoch 15/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 951ms/step - accuracy: 0.8804 - loss: 0.3278 - val_accuracy: 0.8177 - val_loss: 0.4536\nEpoch 1/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 1s/step - accuracy: 0.7490 - loss: 0.7249 - val_accuracy: 0.8444 - val_loss: 0.4190\nEpoch 2/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.8564 - loss: 0.3914 - val_accuracy: 0.8558 - val_loss: 0.3978\nEpoch 3/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1s/step - accuracy: 0.8768 - loss: 0.3380 - val_accuracy: 0.8658 - val_loss: 0.3843\nEpoch 4/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1s/step - accuracy: 0.8805 - loss: 0.3186 - val_accuracy: 0.8688 - val_loss: 0.3752\nEpoch 5/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step - accuracy: 0.8970 - loss: 0.2881 - val_accuracy: 0.8696 - val_loss: 0.3594\nEpoch 6/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.8999 - loss: 0.2507 - val_accuracy: 0.8764 - val_loss: 0.3318\nEpoch 7/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.8992 - loss: 0.2698 - val_accuracy: 0.8795 - val_loss: 0.3262\nEpoch 8/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 1s/step - accuracy: 0.8982 - loss: 0.2563 - val_accuracy: 0.8810 - val_loss: 0.3121\nEpoch 9/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9094 - loss: 0.2337 - val_accuracy: 0.8841 - val_loss: 0.2927\nEpoch 10/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 1s/step - accuracy: 0.9208 - loss: 0.2107 - val_accuracy: 0.8909 - val_loss: 0.2746\nEpoch 11/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9120 - loss: 0.2315 - val_accuracy: 0.8955 - val_loss: 0.2616\nEpoch 12/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step - accuracy: 0.9324 - loss: 0.1846 - val_accuracy: 0.9069 - val_loss: 0.2390\nEpoch 13/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1s/step - accuracy: 0.9276 - loss: 0.1948 - val_accuracy: 0.9130 - val_loss: 0.2163\nEpoch 14/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 1s/step - accuracy: 0.9332 - loss: 0.1787 - val_accuracy: 0.9138 - val_loss: 0.2028\nEpoch 15/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9376 - loss: 0.1773 - val_accuracy: 0.9260 - val_loss: 0.1896\n","output_type":"stream"}],"execution_count":10}]}